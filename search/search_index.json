{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>MAMSI is a Python framework designed for integration of multi-assay mass spectrometry datasets.  In addition, the MAMSI framework provides a platform for linking statistically significant features of untargeted multi-assay liquid chromatography \u2013 mass spectrometry (LC-MS) metabolomics datasets into clusters defined by their structural properties based on mass-to-charge ratio (m/z) and retention time (RT).</p> <p>N.B. the framework was tested on metabolomics phenotyping data, but it be usable with other types of LC-MS data.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Data integration analysis using the Multi-block Partial Least Squares (MB-PLS) algorithm.</li> <li>Multi-block variable importance in projection (MB-VIP).</li> <li>Estimation of statistically significant features (variables) using MB-VIP and permutation testing.</li> <li>Linking significant features into clusters defined by structural properties of metabolites.</li> <li>Feature network links.</li> <li>Annotation of untargeted LC-MS features (Only supported for assays analysed by the National Phenome Centre).</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#dependencies","title":"Dependencies","text":"<ul> <li>mbpls==1.0.4</li> <li>pandas</li> <li>numpy</li> <li>matplotlib</li> <li>scipy</li> <li>scikit-learn</li> <li>seaborn</li> <li>networkx</li> <li>pyvis</li> </ul>"},{"location":"#user-installation","title":"User Installation","text":"<p>You can install MAMSI from source code code given you have installed both Python (&gt;=3.9) and PIP.</p> <p>First, clone the repository from GitHub to your computer. You can use following commands if you have a version of Git installed to your computer:</p> <pre><code>git https://github.com/kopeckylukas/py-mamsi\n\ncd py-mamsi\n</code></pre> <p>When you are in project folder, type following code to install MAMSI and all dependencies:  <pre><code>pip install .\n</code></pre></p> <p>Alternatively, you can install dependencies using pip and MAMSI suing Python: <pre><code>pip install -r requirements.txt\npython setup.py develop\n</code></pre></p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>You can find all MAMSI tutorials by visiting our MAMSI Tutorials repository or follow this quickstart guide.</p> <p>Load Packages <pre><code>from mamsi.mamsi_pls import MamsiPls\nfrom mamsi.mamsi_struct_search import MamsiStructSearch\nimport pandas as pd\nimport numpy as np\n</code></pre></p> <p>Load Sample Data  Data used within this quickstart guide originate from the the AddNeuroMed (S. Lovestone et. al 2009, Ann. N. Y. Acad. Sci.) cohort - dataset of Alzheimer's disease patients.  You can download the sample data from this link.</p> <pre><code>metadata = pd.read_csv('../sample_data/alz_metadata.csv')\n# The PLS algorithm requires the response variable to be numeric. \n# We will encode the outcome \"Gender\" (Biological Sex) as 1 for female and 0 for male subjects. \ny = metadata[\"Gender\"].apply(lambda x: 1 if x == 'Female' else 0)\n\n# Import LC-MS data\n# Add prefix to the columns names. This will be crucial for interpreting the results later on.\nhpos = pd.read_csv('./sample_data/alz_hpos.csv').add_prefix('HPOS_')\nlpos = pd.read_csv('./sample_data/alz_lpos.csv').add_prefix('LPOS_')\nlneg = pd.read_csv('./sample_data/alz_lneg.csv').add_prefix('LNEG_')\n</code></pre> <p>Fit MB-PLS Model and Estimate LVs <pre><code>mamsipls = MamsiPls(n_components=1)\nmamsipls.fit([hpos, lpos, lneg], y_train)\n\nmamsipls.estimate_lv([hpos, lpos, lneg], y_train, metric='auc')\n</code></pre></p> <p>Estimate Feature Importance  You can visualise the Multiblock Variable Importance in Projection (MB-VIP): <pre><code>mb_vip = mamsipls.mb_vip(plot=True)\n</code></pre> or estimate empirical p-values for all features: </p> <pre><code>p_vals, null_vip = mamsipls.mb_vip_permtest([hpos, lpos, lneg], y, n_permutations=10000, return_scores=True)\n</code></pre> <p>Interpret Statistically Significant Features <pre><code>x = pd.concat([hpos, lpos, lneg], axis=1)\n\nmask = np.where(p_vals &lt; 0.01)\nselected = x.iloc[:, mask[0]]\n</code></pre> Use <code>MamsiStrustSearch</code> to search for structural links within the statistically significant features.  Firstly, all features are split into retention time (RT) windows of 5 seconds intervals, then each RT window is searched for isotopologue signature\u2019s by searching mass differences of 1.00335 Da between mass-to-charge ratios (m/z) of the features; if two or more features resemble mass isotopologue signature then they are grouped together. This is followed by a search for common adduct signatures. This is achieved by calculating hypothetical neutral masses based on common adducts in electrospray ionisation. If hypothetical neutral masses match for two or more features within a pre-defined tolerance (15 ppm) then these features are grouped together. Overlapping adduct clusters and isotopologues clusters are then merged to form structural clusters. Further, we search cross-assay clusters using [M+H]<sup>+</sup>/[M-H]<sup>-</sup> as link references. Additionally, our structural search tool, that utilises region of interest (ROI) files from peakPantheR, allows for automated annotation of  some features based on the RT for a given chromatography and m/z.</p> <p><pre><code>struct = MamsiStructSearch(rt_win=5, ppm=10)\nstruct.load_lcms(selected)\nstruct.get_structural_clusters(annotate=True)\n</code></pre> Further, use can find correlation clusters <pre><code>struct.get_correlation_clusters(flat_method='silhouette', max_clusters=11)\n</code></pre> Finally, we visualise the structural relationships using a network plot. The different node colours represent different flattened hierarchical correlation clusters, while the edges between nodes identify their structural links. You can also save the network as an NX object and review in Cytoscape to get better insight on what these the structural relationship between individual features are (e.g. adduct links, isotopologues, cross-assay links). <pre><code>network = struct.get_structural_network(include_all=True, interactive=False, labels=True, return_nx_object=True)\n</code></pre></p>"},{"location":"#issues-and-collaboration","title":"Issues and Collaboration","text":"<p>Thank you for supporting the MAMSI project. MAMSI is an open-source software and welcome any forms of contribution and support.</p>"},{"location":"#issues","title":"Issues","text":"<p>Please submit any bugs or issues via the project's GitHub issue page and any include details about the (<code>mamsi.__version__</code>) together with any relevant input data/metadata. </p>"},{"location":"#collaboration","title":"Collaboration","text":""},{"location":"#pull-requests","title":"Pull requests","text":"<p>You can actively collaborate on MAMSI package by submitting any changes via a pull request. All pull requests will be reviewed by the MAMSI team and merged in due course. </p>"},{"location":"#contributions","title":"Contributions","text":"<p>If you would like to become a contributor on the MAMSI project please contact Lukas Kopecky.</p>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>This package was developed as part of Lukas Kopecky's PhD project at Imperial College London, funded by Waters UK. It is free to use published under BSD 3-Clause licence.</p> <p>The authors of this package would like to acknowledge the authors of the mbpls package which became the backbone of MAMSI. For More information on MB-PLS, please visit MB-PLS Documentation.</p> <p>Further, we would like thank to Prof Simon Lovestone and Dr Shivani Misra for allowing us to use their data for development of this package. </p>"},{"location":"#citing-us","title":"Citing us","text":"<p>If you use MAMSI in a scientific publication, we would appreciate citations. The MAMSI publication is currently under the review process. </p>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#tutorials-and-supporting-materials","title":"Tutorials and Supporting Materials","text":"<p>You can find all MAMSI tutorials by visiting our MAMSI Tutorials repository. </p> <p>The <code>MamsiPls</code> class inherits from the <code>mbpls</code> package [1]. For more information on MB-PLS, please visit mbpls Documentation.</p>"},{"location":"tutorials/#quickstart-tutorial","title":"Quickstart Tutorial","text":""},{"location":"tutorials/#load-packages","title":"Load Packages","text":"<pre><code>from mamsi.mamsi_pls import MamsiPls\nfrom mamsi.mamsi_struct_search import MamsiStructSearch\nimport pandas as pd\nimport numpy as np\n</code></pre>"},{"location":"tutorials/#load-sample-data","title":"Load Sample Data","text":"<p> Data used within this quickstart guide originate from the the AddNeuroMed [2] cohort - dataset of Alzheimer's disease patients.  You can download the sample data from this link.</p> <pre><code>metadata = pd.read_csv('../sample_data/alz_metadata.csv')\n# The PLS algorithm requires the response variable to be numeric. \n# We will encode the outcome \"Gender\" (Biological Sex) as 1 for female and 0 for male subjects. \ny = metadata[\"Gender\"].apply(lambda x: 1 if x == 'Female' else 0)\n\n# Import LC-MS data\n# Add prefix to the columns names. This will be crucial for interpreting the results later on.\nhpos = pd.read_csv('./sample_data/alz_hpos.csv').add_prefix('HPOS_')\nlpos = pd.read_csv('./sample_data/alz_lpos.csv').add_prefix('LPOS_')\nlneg = pd.read_csv('./sample_data/alz_lneg.csv').add_prefix('LNEG_')\n</code></pre>"},{"location":"tutorials/#split-data","title":"Split data","text":"<p>Split the dataset to training and testing subsets. The training subset will be used to fit the model, cross-validation and estimation of the number of latent variables. Then the testing subset will be used as an independent dataset to assess the performance of the model. This will ensure that the model is not over-fitted to the data and that in can predict the outcome of the samples.</p> <pre><code># Split data in the ratio 90:10 for training and testing respectively.\nhpos_train, hpos_test, y_train, y_test = train_test_split(hpos, y, test_size=0.1, random_state=42)\n# Use a 'random_state' value (seed) for reproducibility of results\n\n# Split the other two block based on the indices of the hpos block.\nlpos_train = lpos.iloc[hpos_train.index,:]\nlneg_train = lneg.iloc[hpos_train.index,:]\n\nlpos_test = lpos.iloc[hpos_test.index,:]\nlneg_test = lneg.iloc[hpos_test.index,:]\n</code></pre>"},{"location":"tutorials/#fit-basic-model","title":"Fit Basic Model","text":""},{"location":"tutorials/#fit-mb-pls-model-and-estimate-lvs","title":"Fit MB-PLS Model and Estimate LVs","text":"<p>Start with fitting a simple model utilising one latent variable. Then run the <code>MamsiPls.estimate_lv()</code> method to estimate the number of latent variables in the model. <code>MamsiPls.estimate_lv()</code> uses k-fold cross-validation (CV). The k-fold CV is repeated k-times corresponding to number of LVs in the most complex model. The lowest possible number of LVs where the model stabilised (model performance did not rise with adding more LVs) was selected as the final model. <pre><code>mamsipls = MamsiPls(n_components=1)\nmamsipls.fit([hpos_train, lpos_train, lneg_train], y_train)\n\n# Estimate the number of latent variables in you model\nmamsipls.estimate_lv([hpos_train, lpos_train, lneg_train], y_train, metric='auc')\n</code></pre> The LV estimation result shows that the model has 6 latent variables/components. Adding more LVs to the model could lead into overfitting </p>"},{"location":"tutorials/#evaluate-final-model","title":"Evaluate Final Model","text":"<p>We can now evaluate the final model that utilises 6 LVs. Use <code>MamsiPls.evaluate_class_model()</code> to evaluate the final model on an independent <code>'testing'</code> dataset. </p> <p><pre><code>predicted = mamsipls.evaluate_class_model([hpos_test, lpos_test, lneg_test], y_test.array)\n</code></pre> </p> Metric Score Accuracy 0.966 Recall 1.0 Specificity 0.943 F<sub>1</sub> Score 0.971 AUC 0.933 <p>If the performance of the final model meet our requirements, we can now estimate the the importance of each feature and it's relationship to the outcome.</p>"},{"location":"tutorials/#estimate-feature-importance","title":"Estimate Feature Importance","text":"<p>If the performance of the final model meet our requirements, we can now estimate the the importance of each feature and it's relationship to the outcome.</p>"},{"location":"tutorials/#multiblock-variable-importance-in-projection","title":"Multiblock Variable Importance in Projection","text":"<p>We can visualise the Multiblock Variable Importance in Projection (MB-VIP): <pre><code>mb_vip = mamsipls.mb_vip(plot=True)\n</code></pre> </p> <p>Despite that conventionally features with VIP scores greater than 1 are considered statistically significant, this might not be the most effective cut-off for features importance. Especially in a multiblock model, the block size of each data block play a role to overall importance of each features in the given block.  We can employ permutation testing to estimate empirical p-values for each variable instead. </p>"},{"location":"tutorials/#permutation-testing","title":"Permutation Testing","text":"<p>The empirical p-values for i<sup>th</sup> feature are calculated be dividing the number of MB-VIP scores  of Null model for i<sup>th</sup> feature lower than the observed MB-VIP score for i<sup>th</sup> feature, over the total number of permutations.</p> <p><pre><code>p_vals, null_vip = mamsipls.mb_vip_permtest([hpos, lpos, lneg], y, n_permutations=10000, return_scores=True)\n</code></pre> </p> <p>Note that the pre-calculated null_vip file contains MB-VIP scores for first 400 null models (permutations) so the p-value displayed on the plot below does not correspond with the plot itself.</p>"},{"location":"tutorials/#interpret-statistically-significant-features","title":"Interpret Statistically Significant Features","text":"<p><pre><code>x = pd.concat([hpos, lpos, lneg], axis=1)\n\nmask = np.where(p_vals &lt; 0.01)\nselected = x.iloc[:, mask[0]]\n</code></pre> Use <code>MamsiStrustSearch</code> to search for structural links within the statistically significant features.  Firstly, all features are split into retention time (RT) windows of 5 seconds intervals, then each RT window is searched for isotopologue signature\u2019s by searching mass differences of 1.00335 Da between mass-to-charge ratios (m/z) of the features; if two or more features resemble mass isotopologue signature then they are grouped together. This is followed by a search for common adduct signatures. This is achieved by calculating hypothetical neutral masses based on common adducts in electrospray ionisation. If hypothetical neutral masses match for two or more features within a pre-defined tolerance (15 ppm) then these features are grouped together. Overlapping adduct clusters and isotopologues clusters are then merged to form structural clusters. Further, we search cross-assay clusters using [M+H]<sup>+</sup>/[M-H]<sup>-</sup> as link references. Additionally, our structural search tool, that utilises region of interest (ROI) files from peakPantheR [4], allows for automated annotation of  some features based on the RT for a given chromatography and m/z.</p>"},{"location":"tutorials/#mamsi-structural-search-tool","title":"MAMSI Structural Search Tool","text":"<p><pre><code>struct = MamsiStructSearch(rt_win=5, ppm=10)\nstruct.load_lcms(selected)\nstruct.get_structural_clusters(annotate=True)\n</code></pre> Further, use can find correlation clusters <pre><code>struct.get_correlation_clusters(flat_method='silhouette', max_clusters=11)\n</code></pre> </p> <p>Finally, we visualise the structural relationships using a network plot. The different node colours represent different flattened hierarchical correlation clusters, while the edges between nodes identify their structural links. You can also save the network as an NX object and review in Cytoscape to get better insight on what these the structural relationship between individual features are (e.g. adduct links, isotopologues, cross-assay links). <pre><code>network = struct.get_structural_network(include_all=True, interactive=False, labels=True, return_nx_object=True)\n</code></pre> </p>"},{"location":"references/MamsiPls/","title":"MamsiPls","text":""},{"location":"references/MamsiPls/#mamsipls","title":"MamsiPls","text":"<p>source <pre><code>MamsiPls(\n   n_components = 2, full_svd = False, method = 'NIPALS', standardize = True,\n   max_tol = 1e-14, nipals_convergence_norm = 2, calc_all = True, sparse_data = False,\n   copy = True\n)\n</code></pre></p> <p>Methods:</p>"},{"location":"references/MamsiPls/#estimate_lv","title":".estimate_lv","text":"<p>source <pre><code>.estimate_lv(\n   x, y, n_components = 10, no_fold = 5, y_continuous = False, metric = 'auc',\n   plateau_threshold = 0.01, increase_threshold = 0.05, get_scores = False\n)\n</code></pre></p> <p>Method to estimate the number of latent variables (components) for MAMSI MB-PLS model.</p> <p>Args</p> <ul> <li>x (array or list[array]) : All blocks of predictors x1, x2, ..., xn. Rows are observations, columns are features/variables.</li> <li>y (array) : 1-dim or 2-dim array of reference values, either continuous or categorical variable.</li> <li>n_components (int, optional) : Number of components / latent variables. Defaults to 10.</li> <li>no_fold (int, optional) : Number of folds for k-fold cross-validation. Defaults to 5.</li> <li>y_continuous (bool, optional) : Whether the outcome is a continuous variable. Defaults to False.</li> <li>metric (str, optional) : Metric to use to estimate the number of LVs; available options: ['AUC', 'q2', 'precision', 'recall', 'f1']. Defaults to 'AUC'.</li> <li>plateau_threshold (float, optional) : Maximum increase for a sequence of LVs to be considered a plateau. Must be non-negative. Defaults to 0.01.</li> <li>increase_threshold (float, optional) : Minimum increase to be considered a bend. Must be non-negative. Defaults to 0.05.</li> <li>get_scores (bool, optional) : Whether to return measured scores as a dataframe. Defaults to False.</li> </ul> <p>Returns</p> <ul> <li>DataFrame  : Measured scores as a Pandas dataframe.</li> </ul>"},{"location":"references/MamsiPls/#evaluate_class_model","title":".evaluate_class_model","text":"<p>source <pre><code>.evaluate_class_model(\n   x, y\n)\n</code></pre></p> <p>Evaluate classfication MB-PLS model using a testing dataset.</p> <p>Args</p> <ul> <li>x (array or list[array]) : All blocks of predictors x1, x2, ..., xn. Rows are observations, columns are features/variables.</li> <li>y (array) : 1-dim or 2-dim array of reference values - categorical variable.</li> </ul> <p>Returns</p> <ul> <li>array  : Predicted y variable based on training set predictors.</li> </ul>"},{"location":"references/MamsiPls/#evaluate_regression_model","title":".evaluate_regression_model","text":"<p>source <pre><code>.evaluate_regression_model(\n   x, y\n)\n</code></pre></p> <p>Evaulate regression MB-PLS model using a testing dataset.</p> <p>Args</p> <ul> <li>x (array or list[array]) : All blocks of predictors x1, x2, ..., xn. Rows are observations, columns are features/variables.</li> <li>y (array) : 1-dim or 2-dim array of reference values - continuous variable.</li> </ul> <p>Returns</p> <ul> <li>array  : Predicted y variable based on training set predictors.</li> </ul>"},{"location":"references/MamsiPls/#mb_vip","title":".mb_vip","text":"<p>source <pre><code>.mb_vip(\n   plot = False\n)\n</code></pre></p> <p>Multi-block Variable Importance in Projection (MB-VIP) for multiblock PLS model.</p> <p>Adaptation of C. Wieder et al., (2024). PathIntegrate, doi: 10.1371/journal.pcbi.1011814.</p> <p>Args</p> <ul> <li>plot (bool, optional) : Whether to plot MB-VIP scores. Defaults to False.</li> </ul> <p>Returns</p> <ul> <li>array  : MB-VIP scores.</li> </ul>"},{"location":"references/MamsiPls/#mb_vip_permtest","title":".mb_vip_permtest","text":"<p>source <pre><code>.mb_vip_permtest(\n   x, y, n_permutations = 1000, return_scores = False\n)\n</code></pre></p> <p>Calculate empirical p-values for each feature by permuting the Y outcome variable <code>n_permutations</code> times and refitting the model. The p-values for each feature are then calculated by counting the number of trials with MB-VIP greater than or equal to the observed test statistic, and dividing this by <code>n_permutations</code>.</p> <p>N.B. This method uses OpenMP to parallelise the code, relying on multi-threading exclusively. By default, the implementations using OpenMP will use as many threads as possible, i.e. as many threads as logical cores. This is available by default on systems with macOS and MS Windows. Running this method on a High Performance Computing (HPC) system, including Imperial College London HPC, requires additional Joblib parallelisation. A parallelised permtest function can be found in the ./Extras directory as <code>parallel_mb_vip_permtest.py</code>. If you are an Imperial colleague, do not hesitate to contact me for support on how to set up a PBS file.</p> <p>Args</p> <ul> <li>x (array or list[array]) : All blocks of predictors x1, x2, ..., xn. Rows are observations, columns are features/variables.</li> <li>y (array) : 1-dim or 2-dim array of reference values, either continuous or categorical variable.</li> <li>n_permutations (int, optional) : Number of permutation tests. Defaults to 1000.</li> <li>return_scores (bool, optional) : Whether to return MB-VIP scores for each permuted null model. Defaults to False.</li> </ul> <p>Returns</p> <ul> <li>array  : Returns an array of p-values for each feature. If <code>return_scores</code> is True, then a matrix of MB-VIP scores for each permuted null model is returned as well.</li> </ul>"},{"location":"references/MamsiPls/#_find_plateau","title":"._find_plateau","text":"<p>source <pre><code>._find_plateau(\n   scores, range_threshold = 0.01, consecutive_elements = 3\n)\n</code></pre></p> <p>Function to assist in finding a plateau in a sequence of LVs.</p> <p>Args</p> <ul> <li>scores (list[float]) : List of scores.</li> <li>range_threshold (float, optional) : Maximum increase for a sequence of LVs to be considered a plateau. Defaults to 0.01.</li> <li>consecutive_elements (int, optional) : Number of elements that need to be in a plateau. Defaults to 3.</li> </ul> <p>Returns</p> <ul> <li>tuple  : Beginning and end indices of the plateau.</li> </ul>"},{"location":"references/MamsiStructSearch/","title":"MamsiStructSearch","text":""},{"location":"references/MamsiStructSearch/#mamsistructsearch","title":"MamsiStructSearch","text":"<p>source <pre><code>MamsiStructSearch(\n   rt_win = 5, ppm = 15\n)\n</code></pre></p> <p>A class for performing structural search on LC-MS data using.</p> <p>Attributes</p> <ul> <li>assay_links (list) : List of data frames containing links for each assay.</li> <li>intensities (numpy.ndarray) : Array of LC-MS intensity data.</li> <li>rt_win (int) : Retention time tolerance window.</li> <li>ppm (int) : Mass-to-charge ratio (m/z) tolerance in ppm.</li> <li>feature_metadata (pandas.DataFrame) : Data frame containing feature metadata extracted from column names.</li> </ul> <p>Methods:     get_correlation_clusters(visualise=True): Find correlation clusters for MB-PLS features.</p> <p>Methods:</p>"},{"location":"references/MamsiStructSearch/#load_msi","title":".load_msi","text":"<p>source <pre><code>.load_msi(\n   df\n)\n</code></pre></p> <p>Imports MSI intensity data and extracts feature metadata from column names.</p> <p>Args</p> <ul> <li>df (pandas.DataFrame) : Data frame with MSI intensity data.<ul> <li>rows: samples</li> <li>columns: features (m/z peaks)     Column names in the format:              For example:         149.111"},{"location":"references/MamsiStructSearch/#load_lcms","title":".load_lcms","text":"<p>source <pre><code>.load_lcms(\n   df\n)\n</code></pre></p> <p>Imports LC-MS intensity data and extracts feature metadata from column names.</p> <p>Args</p> <ul> <li>df (pandas.DataFrame) : Data frame with LC-MS intensity data.<ul> <li>rows: samples</li> <li>columns: features (LC-MS peaks)     Column names in the format:         m/z     For example:         HPOS_233.25_149.111m/z"},{"location":"references/MamsiStructSearch/#get_structural_clusters","title":".get_structural_clusters","text":"<p>source <pre><code>.get_structural_clusters(\n   adducts = 'all', annotate = True\n)\n</code></pre></p> <p>Searches structural signatures in LC-MS data based on their m/z and RT. These structural signatures include  isotopologues and adduct patterns.</p> <p>Args</p> <ul> <li>adducts (str, optional) : Define what type of adducts to .      Possible values are:         - 'all': All adducts combinations (based on Fiehn Lab adduct calculator).         - 'most-common': Most common adducts for ESI (based on Waters documentation).     Defaults to 'all'.</li> <li>annotate (bool, optional) : Annotate significant features based on National Phenome Centre RIO data.     Only to be run if the data was analysed by the National Phenome Centre or analysis followed their     conventions and protocls. For more infomrmation see https://doi.org/10.1021/acs.analchem.6b01481      or https://phenomecentre.org.     Uses semi-targeted annotations for selected compounds.     Defaults to True.</li> </ul> <p>Returns</p> <ul> <li>list (pandas.DataFrame) : DataFrame of significant features with structural clusters.</li> </ul>"},{"location":"references/MamsiStructSearch/#get_neutral_mass","title":".get_neutral_mass","text":"<p>source <pre><code>.get_neutral_mass(\n   features, adducts = 'all'\n)\n</code></pre></p> <p>Calculate potential neutral masses for all m/z features.</p> <p>Args</p> <ul> <li>features (pandas.DataFrame) : DataFrame containing m/z features.</li> <li>adducts (str, optional) : DataFrame with ion masses and names. Defaults to 'all'.</li> </ul> <p>Returns</p> <ul> <li>DataFrame  : DataFrame with m/z and hypothetical neutral masses for given adducts.</li> </ul>"},{"location":"references/MamsiStructSearch/#_mean_ppm_diff","title":"._mean_ppm_diff","text":"<p>source <pre><code>._mean_ppm_diff(\n   x, y\n)\n</code></pre></p> <p>Calculates the mean PPM difference between two numbers.</p> <p>Args</p> <ul> <li>x (float) : The first number.</li> <li>y (float) : The second number.</li> </ul> <p>Returns</p> <ul> <li>float  : Mean PPM difference between <code>x</code> and <code>y</code>.</li> </ul>"},{"location":"references/MamsiStructSearch/#get_correlation_clusters","title":".get_correlation_clusters","text":"<p>source <pre><code>.get_correlation_clusters(\n   flat_method = 'constant', cut_threshold = 0.7, max_clusters = 5,\n   cor_method = 'pearson', linkage_method = 'complete', metric = 'euclidian',\n   **kwargs\n)\n</code></pre></p> <p>Clusters features based on their correlation. The method uses hierarchical clustering to create clusters.</p> <p>Args</p> <ul> <li>Flattens clusters based on a constant threshold (cut_threshold).<ul> <li>'silhouette': Flattens clusters based on most optimal silhouette score. Defaults to 'constant'.</li> </ul> </li> <li>cut_threshold (float, optional) : Constant threshold for flattening clusters. Defaults to 0.7.</li> <li>max_clusters (int, optional) : Maximum number of clusters for silhouete method. Defaults to 5.</li> <li>cor_method (str {'pearson', 'kendall', 'spearman'}, optional) : Mehthod for calculation correlations. Defaults to 'pearson'.</li> <li>linkage_method (str, optional) : Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation.     The algorithm will merge the pairs of cluster that minimize this criterion.<ul> <li>'single': Single linkage minimises the maximum distance between observations of pairs of clusters.</li> <li>'complete': Complete linkage minimises the maximum distance between observations of pairs of clusters.</li> <li>'average': Average linkage minimises the average of the distances between all observations of pairs of clusters.</li> <li>'ward': Ward minimises the variance of the clusters being merged.</li> <li>'weighted': Weighted linkage minimises the sum of the product of the distances and the number of observations in pairs of clusters.     Only available for 'constant' flatting method.</li> <li>'centroid': Centroid linkage minimises the distance between the centroids of clusters.     Only available for 'constant' flatting method.</li> <li>'median': Median linkage minimises the distance between the medians of clusters.     Only available for 'constant' flatting method. Defaults to 'complete'.</li> </ul> </li> <li>metric (str, optional) : The distance metric to use. The metric to use when calculating distance between instances in a feature array.     Metric used to compute the linkage. Can be \u201ceuclidean\u201d, \u201cl1\u201d, \u201cl2\u201d, \u201cmanhattan\u201d, \u201ccosine\u201d, or \u201cprecomputed\u201d.     If linkage is \u201cward\u201d, only \u201ceuclidean\u201d is accepted. If \u201cprecomputed\u201d, a distance matrix is needed as input for the fit method.     Defaults to 'euclidian'. flat_method (str {'constant', 'silhouette'}, optional):     Method for cluster flattening:</li> </ul>"},{"location":"references/MamsiStructSearch/#get_structural_network","title":".get_structural_network","text":"<p>source <pre><code>.get_structural_network(\n   include_all = False, interactive = False, return_nx_object = False,\n   output_file = 'interactive.html', labels = False, master_file = None\n)\n</code></pre></p> <p>Generates a structural network graph based on the provided master file or the loaded structural links data.</p> <p>Args</p> <ul> <li>include_all (bool, optional) : Whether to include all features in the network, even if they are not structurally linked to other features.     Defaults to False.</li> <li>interactive (bool, optional) : Whether to display the network graph interactively using pyvis.network.     If False, the network graph is displayed using NetworkX and Matplotlib.     Defaults to False.</li> <li>return_nx_object (bool, optional) : Whether to return the NetworkX object representing the network graph edited in CytoScape.      Defaults to False.</li> <li>output_file (str, optional) : The name of the output file when displaying the network graph interactively using pyvis.network.     Only applicable when interactive is True.      Defaults to 'interactive.html'.</li> <li>labels (bool, optional) : Whether to display labels for the nodes in the network graph.     Only applicable when interactive is False.      Defaults to False.</li> <li>master_file (pd.DataFrame, optional) : The master file containing necessary columns for generating the network.     This is intended for cases when strucutural links required manual curation (e.g. manualy assigned isotopologue groups, adduct groups, etc.)     If not provided, the function uses the loaded structural links data.     Required columns:          - Feature: Feature ID (e.g. HPOS_233.25_149.111m/z)         - Assay: Assay name (e.g. HPOS)         - Isotopologue group (groups features with similar isotopologue patterns)         - Isotopologue pattern (e.g. 0, 1, 2 ... N representing M+0, M+1, M+2 ... M+N)         - Adduct group (groups features with similar adduct patterns)         - Adduct (adduct label, e.g. [M+H]+, [M-H]-)         - Structural cluster (groups features with similar isotopologue and adduct patterns)         - Correlation cluster (flattedned hierarchical cluster from get_correlation_clusters()         - Cross-assay link (links features across different assays)         - cpdName (compound name, optional)     Defaults to None.</li> </ul> <p>Returns</p> <ul> <li>None  : The NetworkX object representing the network graph, if return_nx_object is True.     Edge weights represent the type of link between features:         - Isotopologue: 1         - Adduct: 5         - Cross-assay link: 10     Otherwise, None.</li> </ul> <p>Raises</p> <ul> <li>RuntimeWarning  : If no data is loaded and no master file is provided.</li> <li>RuntimeWarning  : If the provided master file is missing necessary columns.</li> </ul> <p>Notes:     - The function creates a network graph based on the provided master file or the loaded structural links data.     - The network graph includes nodes representing features and edges representing different types of links.     - The graph can be displayed interactively using pyvis.network or using networkx and matplotlib.     - The graph can be saved as a NetworkX object if return_nx_object is True.</p>"}]}